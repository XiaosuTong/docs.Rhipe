## Using a Combiner ##

### The Combiner ###

#### Combiner as an Optimization

Between the map phase and reduce phase of a MapReduce job, Hadoop sends all the intermediate values for a given key to the reducer. The intermediate values for a given key are located on several compute nodes and need to be shuffled (sent across the network) to the node assigned the processing of that intermediate key. This involves a lot of network transfer. 

Some operations do not need access to all of the data (intermediate values), i.e they can compute on subsets and order does not matter, i.e associative and commutative operations. For example, the minimum, or the sum, of some numbers. In these cases, a combiner can be useful.

The idea of the combiner is that the reduce is first run locally on mapper outputs before they are sent for the final reduce. When the combiner is enabled, the reduction occurs just after the map phase on a subset of intermediate values for a given intermediate keys. The output of this is then sent to the reducer. This greatly reduces network transfer and accelerates the job speed, especially if the output from a map contains a lot of data. 


#### Enabling Combiner in RHIPE

Combiner can be enabled in RHIPE by specifying `combiner = TRUE` when calling function `rhwatch()`.

To be able to use a combiner, your **reduce expression needs to pass the same data type as it receives**, i.e the two arguments in the function `rhcollect()` in your map expression need to be of the same type as those in the function `rhcollect()` in your reduce expression. For example, if you pass a string as the key and a numeric vector as the value in the map expression, you need to pass a string as key and a numeric vector as the value in the reduce expression as well.

We will demonstrate the usage of combiners through the following examples.


### Airline Data: Overall Distance by Carrier ###

We will make use of the Airline data introduced in the previous sections, and more specifically, we will use the database of flight information created in the HDFS under `/tmp/airline/output/blocks`.

Recall that in this database, the key is a time interval, and the value is a data frame of information of flights during this time interval. 
Each row of the data frame is a flight, and the flight information are in the columns, including carrier name, distance of flight, and so on.

Suppose we would like to compute the all time distance for each carrier, which is the summation of distance over all flights of each carrier.

#### Without Combiner

First, let's compute the sum without combiner. Here's the RHIPE code for this computation.

```{r eval=FALSE, tidy=FALSE}
# RHIPE code to compute summation of distances for each carrier
map <- expression({
  lapply(map.values, function(r) {
    # r is a data frame with each line being a flight
    # for each flight, collect 
    #   the carrier as the key 
    #   the distance as the value
    Map(rhcollect, r$carrier, r$dist) 
  })
})
reduce <- expression(
  pre = {
    dist = 0
  }, 
  reduce = {
    dist = dist + sum(unlist(reduce.values), na.rm = TRUE)
  },
  post = {
    rhcollect(reduce.key, dist)
  }
)
z <- rhwatch(
  map    = map,
  reduce = reduce,
  input  = "/tmp/airline/output/blocks",
  output = "/tmp/combiner/distance.by.carrier/no.combiner"
)
```

Notice that in the map expression, we used the base R function `Map()` to collect the carrier name as the key and distance of each flight as the value, this is not to be confused with the map in the MapReduce framework.

In the reduce stage, the distances of all the flights from the same carrier have been transmitted to the same reducer. 
So in the reduce expression, we sum up all values of the distance for each carrier as `dist`: 
we first initialize the sum to be 0 in `pre`; 
then we keep adding the sum of `reduce.values`, which is a list of individual flight distances, to `dist` in `reduce`; 
at last, when all flights of the carrier have been aggregated, we collect the `reduce.key`, which is the carrier name, as the key and the aggregated distance as the value in `post`. 
The `na.rm` argument in the function `sum()` is turned on because for some of the flights, the distance field is missing.

We can read the output into the R global environment and transform into a data frame through the following code:

```{r eval=FALSE, tidy=FALSE}
# read the output into the R global environment
rst = rhread("/tmp/combiner/distance.by.carrier/no.combiner")
# form a data frame for carriers and their distances
df = data.frame(  
  carrier  = sapply(rst, "[[", 1),
  distance = sapply(rst, "[[", 2)
)
# re-arrange the data frame by distance
df = df[order(df$distance, decreasing = TRUE), ]  
# re-assign the row names
row.names(df) = NULL
```

And the resulting data frame `df` will look like this, with American Airlines (AA), Delta Airline (DL), and United Airline (UA) being the top 3:

```
   carrier   distance
1       AA 5547694472
2       DL 4951504638
3       UA 4915176282
4       US 3652941933
5       CO 3025408204
6       NW 2948310164
7       TW 1710404680
8       WN 1628292542
9       HP 1075453193
10      AS  602641612
11      EA  557435834
12      PI  331802193
13  PA (1)  213910356
14  ML (1)   47795815
15      PS   30274790
```

For the purpose of comparison, we will keep track of the running time of this job and the size of data shuffled between map phase and reduce phase. Both of the these can be located on the Hadoop JobTracker web interface, and for this job, the running time is 1mins, 54sec and size of data shuffled is 1,151,750,924 bytes. Keep in mind that these numbers depend on the configuration of the cluster on which the jobs are running, so you might get different values.

#### With Combiner

Since summation is one of the associative and commutative operations, a combiner can be used here. Let's enable the combiner. 

Notice that in the above code, both map expression and reduce expression are collecting a string as the key and a numeric as the value, so the condition that **reduce expression passing the same data type as it receives** holds.

All we need to do is to set the argument `combiner` to be `TRUE` when calling function `rhwatch`.

```{r eval=FALSE, tidy=FALSE}
# enabling combiner
z2 <- rhwatch(
  map      = map,
  reduce   = reduce,
  input    = "/tmp/airline/output/blocks",
  output   = "/tmp/combiner/distance.by.carrier/yes.combiner",
  combiner = TRUE
)
```

We can read the output into the R global environment and transform the output into a data frame in the same way:

```{r eval=FALSE, tidy=FALSE}
rst2 = rhread("/tmp/combiner/distance.by.carrier/yes.combiner")
df2 = data.frame(  
  carrier  = sapply(rst2, "[[", 1),
  distance = sapply(rst2, "[[", 2)
)
df2 = df2[order(df2$distance, decreasing = TRUE), ]  
row.names(df2) = NULL
```

Just to verify that using the combiner does not alter the result, we can compare `df2` with `df` from the previous job without combiner:
```{r eval=FALSE, tidy=FALSE}
identical(df, df2)
```
```
[1] TRUE
```

We can once again refer to the Hadoop JobTracker web interface, and now the running time of the job with combiner is 1mins, 42sec, and the size of data shuffled is 10,656 bytes. 

After enabling the combiner, the size of data shuffled has seen significantly reduced, from around 1 GB to 10 KB; and the running timing has also decreased by about 10 seconds. The decrease in running time is not drastic simply because the size of data in this example (less than 4 GB) is relatively small compared with the capacity of the cluster, more specifically, the network bandwidth between servers is 1 GB/sec and it wouldn't take much time even if the whole dataset were to be shuffled. 

The combiner really isn't useful with this tiny data set, but it can be very powerful. For example, on a project we are working on looking at packets from Internet connections, we have one connection with over 60 million packets, where each packet corresponds to a row in a data frame. One of our tasks is to create a data set that contains the first 1500 packets from each connection. The connection data are stored by 10,000 packet chunks by connection. To get the first 1500 packets, the first 1500 packets from each chunk are extracted and sent to the reducer, which combines these and sorts again to retrieve the first 1500 packets. For the large connection, there would be over 6,000 maps passing the same key with 1500 observations each. Without using a combiner, the reducer would receive over 9 million records to sort for this connection, and the job takes a very long time to complete. Using a combiner breaks this down and speeds things up dramatically.



### Airline Data: Average Distance per Flight ###

We have demonstrated the usage of the combiner to compute the summation of some numbers in the above example, and all we had to do is to simply turn it on. However, care needs to be taken to make sure that using a combiner does produce the same result as it would without a combiner.

For example, if we were to compute the average distance per flight instead of the sum, we need to do a bit more than just turning on combiner, assuming we replace the function `sum()` with `mean()` of course. This is due to fact that the average of subset averages, which are computed by combiners, is not necessarily the same as the overall average. 

However, this does not prevent us from taking advantage of the combiner, we just need a quick detour: instead of computing the average directly in RHIPE, we could compute the summation and number of values; and then we could read in the output and compute the average in the R global environment.

The computation of summation of distances and number of flights can be done through the following RHIPE code: 

```{r eval=FALSE, tidy=FALSE}
# RHIPE code to compute average distance per flight for each carrier
map <- expression({
  lapply(map.values, function(r) {
    # for each flight, collect 
    #   the carrier as the key 
    #   the distance and flight count as the value
    dist.count = Map(c, r$dist, as.numeric(!is.na(r$dist)))
    Map(rhcollect, r$carrier, dist.count) 
  })
})
reduce <- expression(
  pre = {
    dist = 0
    count = 0
  }, 
  reduce = {
    dist = dist + sum(sapply(reduce.values, "[[", 1), na.rm = TRUE)
    count = count + sum(sapply(reduce.values, "[[", 2), na.rm = TRUE)
  },
  post = {
    rhcollect(reduce.key, c(dist, count))
  }
)
z <- rhwatch(
  map      = map,
  reduce   = reduce,
  input    = "/tmp/airline/output/blocks",
  output   = "/tmp/combiner/average.distance.by.carrier",
  combiner = TRUE
)
```

In the map expression, we have altered the values being collected from the previous example: 
instead of collecting the distance for each flight alone, we collect both the distance and the number of flights being aggregated, which is set to 0 if the distance is missing and thus this flight does not contribute to the sum or average distance, and 1 otherwise. 
This is to make sure that the map expression outputs same data type as the reduce expression. 
We first create a list object `dist.count`, each element of which is a numeric vector of length two, consisting the distance of a flight and the number 1; 
then we collect the carrier of each flight as the key, and each element in `dist.count` as the value. 

In the reduce expression, we sum up distances as `dist` and numbers of flights as `count`, and collect the carrier name as the key, and the vector of aggregated distance and number of flights as the value.

We can read the output into the R global environment and transform into a data frame through the following code:

```{r eval=FALSE, tidy=FALSE}
# read the output into the R global environment
rst = rhread("/tmp/combiner/average.distance.by.carrier")
# form a data frame
df = data.frame(  
  carrier  = sapply(rst, "[[", 1),
  do.call("rbind", lapply(rst, "[[", 2))
)
# re-name the columns of the data frame
names(df) = c("carrier", "distance", "flights")
```

Now that we have computed the aggregated distance and number of flights for each carrier, the average distance per flight can be easily computed as the ratio of the two:

```{r eval=FALSE, tidy=FALSE}
# compute average distance per flight
transform(df, average = distance / flights)
```

```
   carrier   distance flights  average
1       AA 5547694472 6602267 840.2711
2       AS  602641612  965798 623.9831
3       CO 3025408204 4012874 753.9255
4       DL 4951504638 7829867 632.3868
5       EA  557435834  917232 607.7370
6       HP 1075453193 1806551 595.3074
7       NW 2948310164 4405188 669.2813
8       PI  331802193  873957 379.6551
9       PS   30274790   83617 362.0650
10      TW 1710404680 2417453 707.5234
11      UA 4915176282 5931255 828.6908
12      US 3652941933 7284227 501.4866
13      WN 1628292542 4207081 387.0362
14  ML (1)   47795815   70622 676.7837
15  PA (1)  213910356  315075 678.9188
```

