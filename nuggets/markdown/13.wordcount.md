## Word Count Example ##

### The Problem ###

Word count example is a problem of counting the number of occurrences of each word in a large collection of documents.
Now let us start to look at how to do this by using RHIPE package in R. 

### Preparation ###

First we have to get the text files that we want to study on. Please download your favorite Shakespeare plays from 
http://shakespeare.mit.edu/ and save it to a text file or many files. We grab one of the Poetries, A Lover's Complaint, 
and save into two text files to the working directory. 

```r
list.files("./")
```

```
[1] "ALoversComplaint01.txt" "ALoversComplaint02.txt"
```
In these two text files, we remove all space lines, as well as all arbitary spaces before 
any line. Here is how they look like:

```r
system("head ALoversComplaint01.txt")
```

```
A Lover's Complaint
FROM off a hill whose concave womb reworded
A plaintful story from a sistering vale,
My spirits to attend this double voice accorded,
And down I laid to list the sad-tuned tale;
Ere long espied a fickle maid full pale,
Tearing of papers, breaking rings a-twain,
Storming her world with sorrow's wind and rain.
Upon her head a platted hive of straw,
Which fortified her visage from the sun,
```
After the texts are ready, we are going to write them to the HDFS. Originally, there is an empty directory on HDFS named 
`/tmp/wordcount/input`. `rhput()` function is the one will be used to write files onto HDFS. The first argument is the path to the 
local file to be copied to the HDFS, and the second argument is path to the file on the HDFS. After that, We can use `rhls()` 
to access the content under a specific path on HDFS. Information of files such as permission, owner, group, will be displayed.
Becides the path of directory on HDFS to be the first argument of `rhls()`, argument `recurse` can be set to be TRUE, which
will list all files and directories in sub-directories, argument `nice` can be set to be one of `g`,`m`,`b` or `h` (gigabytes, 
megabytes, bytes, human readable)

```r
rhput("~/ALoversComplaint01.txt", "/tmp/wordcount/input/ALoversComplaint01.txt")
rhls("/tmp/wordcount/input")
```

```
  permission owner      group     size          modtime
1 -rw-r--r-- tongx supergroup 7.708 kb 2014-06-08 10:40
2 -rw-r--r-- tongx supergroup 6.271 kb 2014-06-08 10:40
                                         file
1 /tmp/wordcount/input/ALoversComplaint01.txt
2 /tmp/wordcount/input/ALoversComplaint02.txt
```
Text file is an acceptable file format in Mapreduce. If the type of input file in a mapreduce job is "text", RHIPE will 
actually generate a key/value pair for every row. The key is the row index, and the value is the content of corresponding 
line which saved as a string. 

### Entirety ###

The entire code of RHIPE for word count is:

```r
map1 <- expression({
  lapply(seq_along(map.keys), function(r) {
    line = gsub("[[:punct:]]", "", map.values[[r]])
    line = strsplit(line, split=" +")[[1]]
    lapply(line, function(word) {
      rhcollect(word, 1)
    })
  })
})
reduce1 <- expression(
  pre = {
    count = 0
  },
  reduce = {
    count = count + sum(unlist(reduce.values))
  },
  post = {
    rhcollect(reduce.key, count)
  }
)
mr1 <- rhwatch(
  map      = map1,
  reduce   = reduce1,
  input    = rhfmt("/tmp/wordcount/input/ALoversComplaint01.txt",type="text"),
  output   = rhfmt("/tmp/wordcount/output/word.count", type="sequence"),
  mapred   = list( mapred.reduce.tasks=5 ),
  readback = FALSE
)
```

A valid mapreduce job in RHIPE is consist of a `map` expression, an optional `reduce` expression, and a execution funtion 
`rhwatch()`. Right now you do not have to worry too much about the details of map and reduce expressions, we will discrib 
more details in later sessions. Here you can just run this code in R. In R console you will see that job running information
is keeping popping out, which will be helpful for you to have some idea about the status of running job. 
```
Waiting 5 seconds
[Mon Jun  9 09:12:09 2014] Name:2014-06-09 09:11:59 Job: job_201405301308_0844  State: RUNNING Duration: 10.318
URL: http://deneb.stat.purdue.edu:50030/jobdetails.jsp?jobid=job_201405301308_0844
       pct numtasks pending running complete killed failed_attempts killed_attempts
map      1        1       0       0        1      0               0               0
reduce   0        5       0       5        0      0               0               0
Waiting 5 seconds
[Mon Jun  9 09:12:14 2014] Name:2014-06-09 09:11:59 Job: job_201405301308_0844  State: RUNNING Duration: 15.364
URL: http://deneb.stat.purdue.edu:50030/jobdetails.jsp?jobid=job_201405301308_0844
       pct numtasks pending running complete killed failed_attempts killed_attempts
map      1        1       0       0        1      0               0               0
reduce   0        5       0       5        0      0               0               0`
```

After the job is successfully executed, you can access the output on HDFS by calling `rhread()` function. 

```r
rhls("/tmp/wordcount/output")
```

```
  permission owner      group size          modtime                             file
1 drwxr-xr-x tongx supergroup    0 2014-06-09 10:23 /tmp/wordcount/output/word.count
```

```r
rst1 <- rhread("/tmp/wordcount/output/word.count")
head(rst1, 3)
```

```
[[1]]
[[1]][[1]]
[1] "I"

[[1]][[2]]
[1] 10


[[2]]
[[2]][[1]]
[1] "He"

[[2]][[2]]
[1] 1


[[3]]
[[3]][[1]]
[1] "In"

[[3]][[2]]
[1] 3
```
As you can see, the class of the result is a list. Each element of the list is a list with two elements. The first 
element is a word, the second element is a integer. It is obvious to claim that this is a pair of unique word and
its corresponding occurence. The length of `rst1` is the total number of unique word in the text file.

```r
length(rst1)
```

```
[1] 745
```
Of course, the class of output object, which is a list, may not be convenient for further analysis in R. It is easy 
to convert list to be a data.frame in R.

```r
data <- data.frame(key=unlist(lapply(rst1, "[[", 1)), value=unlist(lapply(rst1, "[[",2)))
data <- data[with(data, order(value, decreasing=TRUE)),]
head(data)
```

```  
    key value
303  in    38
456 and    36
7    of    31
16  his    30
323 the    30
603  to    27
```
The final output is converted to be a data.frame, and the words also are ordered by its occurences decreasingly. In the
next map session, we will give more details about the map function in the mapreduce job we just had.

### Map ###

Map is an R expression that is evaluated by RHIPE during the map stage. For each task, RHIPE will call this expression 
multiple times. The input and output of map function are both key/value pairs. A key/value pair (KVP) is an abstract data 
type that includes a group of key identifiers and a set of associated values. In other words, the map function processes a 
key/value pair to generate a set of intermediate key/value pairs. So in our previous map function, we process the key/value 
pairs we got from the text file into new key/value pairs which every word is the key, and the corresponding value would 
be integer 1. The key/value pairs read in from input file will be saved as map.keys and map.values respectively. Map.keys 
and map.values are two lists which are consist of all keys and all values that will be excuted in one task at one monment 
respectively. In this example, which the input file of a mapreduce job is a text file, all keys (indices) in map.keys will 
not have any meaning but will be unique, and all the corresponding values in map.values are each row of text file saved as 
a string.

```r
map1 <- expression({
  lapply(seq_along(map.keys), function(r) {
    line = gsub("[[:punct:]]", "", map.values[[r]])
    line = strsplit(line, split=" +")[[1]]
    lapply(line, function(word) {
      rhcollect(word, 1)
    })
  })
})
```

So in map expression, we iterate over all key/value pairs. The length of map.keys and map.values are the same as the total
number of key/value pairs, which here is the number of row in text file. `map.keys[[r]]` and `map.values[[r]]` is the r'th
key/value pair. For each `map.values[[r]]`, we remove all those special character in each row from the string by using `gsub()`
function. And then we split the `line` by spaces using `strsplit()` function, collect a new key/value pair, which key is a 
single word and value is 1, by using `rhcollect()` function in RHIPE. The first argument of `rhcollect()` is the key, and the
second argument is the value. Suppose we have 100 rows, and each row has 20 words, by using our map function, we will be
collecting 2,000 new key/value pairs, or we call them intermediate key/value pairs.

As we mentioned previously, the reduce expression is optional, and this can be helpful for us if you are interested map.keys
and map.values from text file, or the intermediate key/value pairs after the map expression. Let us first look at the map.keys
and map.values. In map expression, we can just collect one key/value pair. Key is a meaningless integer like 1, value is a list
with two elements named 'keys' and 'values', which are asigned with `map.keys` list and `map.values` list respectively.


```r
map2 <- expression({
  rhcollect(1, list(keys=map.keys, values=map.values))
})
mr2 <- rhwatch(
  map      = map2,
  input    = rhfmt("/tmp/wordcount/input/ALoversComplaint01.txt", type = "text"),
  output   = rhfmt("/tmp/wordcount/output/map", type = "sequence"),
  mapred   = list( mapred.reduce.tasks = 10 ),
  readback = FALSE
)
rst2 <- rhread("/tmp/wordcount/output/map")
```

The `rst2` is a list with one element because there is only one key/value pair been collected in map step. `rst2[[1]][[1]]` is the 
key, and `rst2[[1]][[2]]` is the value.

```r
str(rst2[[1]][[2]])
```

```
List of 2
 $ keys  :List of 185
  ..$ : num 0
  ..$ : num 20
  ..$ : num 64
  ..$ : num 105
...
 $ values:List of 185
  ..$ : chr "A Lover's Complaint"
  ..$ : chr "FROM off a hill whose concave womb reworded"
  ..$ : chr "A plaintful story from a sistering vale,"
  ..$ : chr "My spirits to attend this double voice accorded,"
...
```
Another way to demonstrate the `map.keys` and `map.values` is to collect every element in `map.keys` and `map.values` as a key/value 
pair, and then output them.

```r
map3 <- expression({
  lapply(seq_along(map.keys), function(r){
    rhcollect(map.keys[[r]], map.values[[r]])
  })
})
mr3 <- rhwatch(
  map      = map3,
  input    = rhfmt("/tmp/wordcount/input/ALoversComplaint01.txt", type = "text"),
  output   = rhfmt("/tmp/wordcount/output/identity.map", type = "sequence"),
  mapred   = list( mapred.reduce.tasks = 10 ),
  readback = FALSE
)
rst3 <- rhread("/tmp/wordcount/output/identity.map")
head(rst3, 3)
```

```
[[1]]
[[1]][[1]]
[1] 2190

[[1]][[2]]
[1] "And often kiss'd, and often 'gan to tear:"


[[2]]
[[2]][[1]]
[1] 154

[[2]][[2]]
[1] "And down I laid to list the sad-tuned tale;"


[[3]]
[[3]][[1]]
[1] 4169

[[3]][[2]]
[1] "If best were as it was, or best without."
```
The result is a list with length equals to 185, which is the number of rows in total. Each element is also a 
list with length two. The first element is key, and the second element is value. The map step above can be called
as identity map function, since the input and output key/value pairs of this map function are the same.

### Reduce ###

The next thing we would like to dig into is a reduce function in our mapreduce job. In RHIPE, reduce is an R expression that is evaluated 
by RHIPE during the reduce stage, or it is a vector of expressions with names pre, reduce, and post. All key/value pairs that 
share same key will be grouped together and processed to be applied reduce funtion. In reduce-pre session, we initialize the occurrence 
`count` for each unique word to be 0. `reduce.key` is the shared key, and reduce.values is a list that includes all values corresponding to 
that unique reduce.key. In reduce-reduce session, we cumulative all reduce.values. Finally in post session, we collect the final key/value 
pair for each unique word.


```r
reduce1 <- expression(
  pre = {
    count = 0
  },
  reduce = {
    count = count + sum(unlist(reduce.values))
  },
  post = {
    rhcollect(reduce.key, count)
  }
)
```


It is acceptable to only have reduce session in reduce function. Similar in map step, we can have a reduce expression that only have 
reduce-reduce session to collect `reduce.key` and corresponding `reduce.values`, which can help us to demonstrate the `reduce.key` and
`reduce.values`.


```r
reduce2 <- expression(
  reduce = {
    rhcollect(reduce.key,reduce.values) 
  }
)
mr4 <- rhwatch(
  map      = map1,
  reduce   = reduce2,
  input    = rhfmt("/tmp/wordcount/input/ALoversComplaint01.txt", type = "text"),
  output   = rhfmt("/tmp/wordcount/output/reduce", type = "sequence"),
  mapred   = list( mapred.reduce.tasks = 5 ),
  readback = FALSE
)
rst4 <- rhread("/tmp/wordcount/output/reduce")
str(rst4[[1]])
```

```
List of 2
 $ : chr "I"
 $ :List of 10
  ..$ : num 1
  ..$ : num 1
  ..$ : num 1
  ..$ : num 1
  ..$ : num 1
  ..$ : num 1
  ..$ : num 1
  ..$ : num 1
  ..$ : num 1
  ..$ : num 1
```
The result `rst4` is a list with 745 elements, each is a key/value pair for one unique word. When intermediate key/value pairs are passed
into reduce step, all key/value pairs that share same key are grouped together, then all corresponding values are also grouped to be a list, 
which is the `reduce.values`, as in the example, the `reduce.values` for key 'I' is a list with length 10, and each one is integer 1.

It is also possible to have an identity reduce function that write all intermediate key/value pairs to disk without doing anything else.

```r
reduce3 <- expression(
  reduce = {
    lapply(reduce.values, function(r) rhcollect(reduce.key,r)) 
  }
)
mr5 <- rhwatch(
  map      = map1,
  reduce   = reduce3,
  input    = rhfmt("/tmp/wordcount/input/ALoversComplaint01.txt", type = "text"),
  output   = rhfmt("/tmp/wordcount/output/identity.reduce", type = "sequence"),
  mapred   = list( mapred.reduce.tasks = 5 ),
  readback = FALSE
)
rst5 <- rhread("/tmp/wordcount/output/identity.reduce")
```

The result is still a list with length 1425. This is the total number of words in the text file. Each element
is a list of key/value pair.

```r
length(rst5)
```

```
[1] 1425
```

```r
head(rst5, 3)
```

```
[[1]]
[[1]][[1]]
[1] "I"

[[1]][[2]]
[1] 1


[[2]]
[[2]][[1]]
[1] "I"

[[2]][[2]]
[1] 1


[[3]]
[[3]][[1]]
[1] "I"

[[3]][[2]]
[1] 1
```

### Execution Function ###

After the map and reduce expression, we are heading to the execution function of a mapreduce job in RHIPE.
`rhwatch()` is a call that packages the MapReduce job which is sent to Hadoop. 
In `rhwatch()` function, we specify what the map and reduce stage of the mapreduce job is, which are the expressions
we defined. We asign the map and reduce expression to `map` and `reduce` argument in `rhwatch()` respectively. Input and 
output argument in `rhwatch()` function is used to specify the path on HDFS of input file and output file respectively, and 
there are three types of file we can consider, text, sequence, and map file. Mapred argument is a list that can be used to 
customize the Hadoop and RHIPE options. Here we specify the `mapred.reduce.tasks` to be 5 or 10, so the number of reduce tasks will 
be set to be 5 or 10. This number also is related to the number of output files, since each reduce task will generate one piece
of output file for the final output. 

```r
mr1 <- rhwatch(
  map      = map1,
  reduce   = reduce1,
  input    = rhfmt("/tmp/wordcount/input/ALoversComplaint01.txt",type="text"),
  output   = rhfmt("/tmp/wordcount/output/word.count", type="sequence"),
  mapred   = list( mapred.reduce.tasks=5 ),
  readback = FALSE
)
```

In `mr1` job, we specify `mapred.reduce.tasks` to be 5, so there will be five files in output
"/tmp/wordcount/output/word.count", named from "part-r-00000" to "part-r-00004". Besides these five files, there will be
another two files named "_SUCCESS" and "_logs" which records the metadata and log information.

```r
rhls("/tmp/wordcount/output/word.count")
```

```
  permission owner      group     size          modtime
1 -rw-r--r-- tongx supergroup        0 2014-06-09 10:23
2 drwxr-xr-x tongx supergroup        0 2014-06-09 10:23
3 -rw-r--r-- tongx supergroup 4.966 kb 2014-06-09 10:23
4 -rw-r--r-- tongx supergroup  5.01 kb 2014-06-09 10:23
5 -rw-r--r-- tongx supergroup 4.878 kb 2014-06-09 10:23
6 -rw-r--r-- tongx supergroup 5.177 kb 2014-06-09 10:23
7 -rw-r--r-- tongx supergroup 4.928 kb 2014-06-09 10:23
                                           file
1     /tmp/wordcount/output/word.count/_SUCCESS
2        /tmp/wordcount/output/word.count/_logs
3 /tmp/wordcount/output/word.count/part-r-00000
4 /tmp/wordcount/output/word.count/part-r-00001
5 /tmp/wordcount/output/word.count/part-r-00002
6 /tmp/wordcount/output/word.count/part-r-00003
7 /tmp/wordcount/output/word.count/part-r-00004
```
If we go to the output directory of output from `mr2`, which we specify the `mapred.reduce.tasks` to be 10, we will find without
surprise that there are ten files plus "_SUCCESS and "_logs"

```r
rhls("/tmp/wordcount/output/map")
```

```
   permission owner      group        size          modtime
1  -rw-r--r-- tongx supergroup           0 2014-06-09 11:42
2  drwxr-xr-x tongx supergroup           0 2014-06-09 11:42
3  -rw-r--r-- tongx supergroup    11.66 kb 2014-06-09 11:42
4  -rw-r--r-- tongx supergroup    94 bytes 2014-06-09 11:42
5  -rw-r--r-- tongx supergroup    94 bytes 2014-06-09 11:42
6  -rw-r--r-- tongx supergroup    94 bytes 2014-06-09 11:42
7  -rw-r--r-- tongx supergroup    94 bytes 2014-06-09 11:42
8  -rw-r--r-- tongx supergroup    94 bytes 2014-06-09 11:42
9  -rw-r--r-- tongx supergroup    94 bytes 2014-06-09 11:42
10 -rw-r--r-- tongx supergroup    94 bytes 2014-06-09 11:42
11 -rw-r--r-- tongx supergroup    94 bytes 2014-06-09 11:42
12 -rw-r--r-- tongx supergroup    94 bytes 2014-06-09 11:42
                                     file
1      /tmp/wordcount/output/map/_SUCCESS
2         /tmp/wordcount/output/map/_logs
3  /tmp/wordcount/output/map/part-r-00000
4  /tmp/wordcount/output/map/part-r-00001
5  /tmp/wordcount/output/map/part-r-00002
6  /tmp/wordcount/output/map/part-r-00003
7  /tmp/wordcount/output/map/part-r-00004
8  /tmp/wordcount/output/map/part-r-00005
9  /tmp/wordcount/output/map/part-r-00006
10 /tmp/wordcount/output/map/part-r-00007
11 /tmp/wordcount/output/map/part-r-00008
12 /tmp/wordcount/output/map/part-r-00009
```
Here you may find out that there are 9 output files are with size of 94 bytes, and only one is 11.66 Kb. The reason for this is 
because in `mr2`, we only collect one key/value pair, and one key/value pair cannot be split to multiple files. But we do specify
that we want 10 output files. So this only key/value pair is saved into one file, and the rest of files will be empty file with 
fixed size, 94 bytes. If the number of reduce tasks is specified larger than the number of key/value pairs, some of files will
be empty. `readback` argument in `rhwatch()` is a logical argument that controls if the results of mapreduce job will be read 
back. 

### Combiner ###

After map function is finished, there may be significant repetition in the intermediate keys produced by each map task.
For our example here, it is highly possible that each map task will produce hundreds or thousands of records of the form
(the, 1). All of these counts will be sent over the network to a single reduce task and then added together by the reduce 
function to produce one number. A better way to speed up this mapreduce job is try to eliminate the objects that need to 
be transferred. So we can specify an optional combiner function that does partial merging of intermediate key/value pairs
before it is sent over the network.

The combiner function is executed on each machine that performs a map task. Typically the same code is used to implement 
both the combiner and the reduce functions.

```r
mr6 <- rhwatch(
  map      = map1,
  reduce   = reduce1,
  input    = rhfmt("/tmp/wordcount/input/ALoversComplaint01.txt",type="text"),
  output   = rhfmt("/tmp/wordcount/output/combiner", type="sequence"),
  mapred   = list( mapred.reduce.tasks=5 ),
  combiner = TRUE,
  readback = FALSE,
)
rst6 <- rhread("/tmp/wordcount/output/combiner")
```


Technically, the number of input key/value pairs to reduce function is smaller when we active the combiner function. One way
to check this is that we can go to the jobtracker webpage, one of counter named "Reduce input records" tells us how many
input key/value pairs to the reduce function. For previous example, the "Reduce input records" counter is 1,425. When we 
consider the combiner function, the "Reduce input records" counter is 745. So combiner function does help us to eliminate
the number of key/value pairs to be transported from map to reduce.

### Multiple input files ###

It is quite common that we have more than one input files. RHIPE allows us to have a vector of path string to be input. For
this situation, you can specify the input as a input directory which includes all input files. If a particular file cannot be
understood by the input format (e.g. a text file given to `type=sequence`), RHIPE will throw an error. 

```r
mr7 <- rhwatch(
  map      = map1,
  reduce   = reduce1,
  input    = rhfmt("/tmp/wordcount/input", type="text"),
  output   = rhfmt("/tmp/wordcount/output/total", type="sequence"),
  mapred   = list( mapred.reduce.tasks=5 ),
  readback = FALSE,
  combiner = TRUE,
)
rst7 <- rhread("/tmp/wordcount/output/total")
```


```r
length(rst7)
```

```
[1] 1171
```

```r
head(rst7, 3)
```

```
[[1]]
[[1]][[1]]
[1] "I"

[[1]][[2]]
[1] 20


[[2]]
[[2]][[1]]
[1] "He"

[[2]][[2]]
[1] 2


[[3]]
[[3]][[1]]
[1] "In"

[[3]][[2]]
[1] 8
```
Still, we can easily transform the output list to be a data.frame for further analysis.

```r
data <- data.frame(key = unlist(lapply(rst7, "[[", 1)), value = unlist(lapply(rst7, "[[",2)))
data <- data[with(data, order(value, decreasing=TRUE)),]
head(data)
```

```
    key value
721 and    63
8    of    58
508 the    57
483  in    55
951  to    51
17  his    40
```

