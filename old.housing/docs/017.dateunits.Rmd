### Compute Total Sold Units ###

We then would like to calculate the total sold units for every month based on the month division.
One thing we should keep in mind about the month division is that we have 6 subsets for each month.
And this will be the main reason that we want to consider one of the optimization method in `RHIPE`.

#### Combiner as an Optimization ####

Between the map phase and reduce phase of a MapReduce job, Hadoop sends all the intermediate values
for a given key to the reducer. The intermediate values for a given key are located on several compute 
nodes and need to be shuffled (sent across the network) to the node assigned the processing of that
intermediate key. This involves a lot of network transfer.

Some operations do not need access to all of the data (intermediate values), i.e they can compute on 
subsets and order does not matter, i.e associative and commutative operations. For example, the minimum, 
or the sum, of some numbers. In these cases, a combiner can be useful.

The idea of the combiner is that the reduce is first run locally on mapper outputs before they are sent 
for the final reduce. When the combiner is enabled, the reduction occurs just after the map phase on a 
subset of intermediate values for a given intermediate keys. The output of this is then sent to the 
reducer. This greatly reduces network transfer and accelerates the job speed, especially if the output 
from a map contains a lot of data.

#### Enabling Combiner in RHIPE ####

Combiner can be enabled in `RHIPE` by specifying `combiner = TRUE` when calling function `rhwatch()`.

To be able to use a combiner, our reduce expression needs to pass the same data type as it receives,
i.e the two arguments in the function rhcollect() in your map expression need to be of the same type as 
those in the function rhcollect() in your reduce expression. For example, if you pass a string as the key
and a numeric vector as the value in the map expression, you need to pass a string as key and a numeric 
vector as the value in the reduce expression as well.

We will demonstrate the usage of combiners through the following examples. First, let us look at how to 
achieve this task without using a combiner.

#### Without Combiner ####

```{r eval=FALSE, tidy=FALSE}
map6 <- expression({
  lapply(seq_along(map.keys), function(r) {
    key <- map.keys[[r]]
    value <- sum(as.numeric(map.values[[r]]$units), na.rm = TRUE)
    rhcollect(key, value)
  })
})
```

In the map expression, we calculated the sum of the sold units for each subset. Since month index is the
input key, and we have 6 subsets for each key, there will be 6 key-value pairs for each month. The value
of each key-value pair is the summation of number of sold units in corresponding subset. So totally there
will be 396 intermediate key-value pairs as output of map expression.

```{r eval=FALSE, tidy=FALSE}
reduce6 <- expression(
  pre = {
    count <- 0
  },
  reduce = {
    count <- count + sum(unlist(reduce.values), na.rm = TRUE)
  },
  post = {
    rhcollect(reduce.key, count)
  }
)
```

Then in the reduce expression, we grouped all 6 summation for each unique key(month index), and calculated
the overall summation for each month

```{r eval=FALSE, tidy=FALSE}
mr6 <- rhwatch(
  map       = map6,
  reduce    = reduce6,
  input     = rhfmt("/ln/tongx/housing/bydate", type = "sequence"),
  output    = rhfmt("/ln/tongx/housing/soldbydate", type = "sequence"),
  mapred    = list(
    mapred.reduce.tasks = 10
  ),
  jobname   = "total sold unit for each month",
  mon.sec   = 10,
  combiner  = FALSE,
  readback  = FALSE
)
```

The default for combiner is `FALSE`, which is what we have used before. We also specified two more
arguments in `rhwatch` which are `mon.sec` and `jobname`. Both of them are easy to understand. `mon.sec`
is a numeric integer which specifies how often in terms of second the job status will be reported in R after
the job is submitted. As we seen in "Division by State" session, after job is submitted, we would see job
status every 5 seconds which is the default value of `mon.sec`. `jobname` is a string that we can used to 
name our job. The default job name is the date and time when job is submitted.

#### With Combiner ####

Now let us see how to do the same task with combiner.

```{r eval=FALSE, tidy=FALSE}
mr7 <- rhwatch(
  map       = map6,
  reduce    = reduce6,
  input     = rhfmt("/ln/tongx/housing/bydate", type = "sequence"),
  output    = rhfmt("/ln/tongx/housing/soldbydate.combiner", type = "sequence"),
  mapred    = list(
    mapred.reduce.tasks = 10
  ),
  jobname   = "total sold unit for each month with combiner",
  mon.sec   = 10,
  combiner  = TRUE,
  readback  = FALSE
)
```

The map and reduce expression for combiner situation will be exactly same as the situation without combiner.
The only difference is that we changed the `combiner` argument in `rhwatch` to be `TRUE` to active the 
combiner. So what happened when combiner was active was nothing but each mapper(server or node that ran map
expression) run the reduce expression before it generated intermediate key-value pairs.

For this example,
one of the mapper may generated two out of six summation for one month. Without combiner, these two 
summation will be transferred with other four summation which calculated on another mapper to one reducer
(server or node that ran reduce expression). With combiner, however, these two summation will be first 
summed up together then only one key-value pairs will be transferred to the reducer instead of two. This
will be a huge difference with respect to transferring time when we have very many or very large size of 
values related to one key.

Finally, we can double check if combiner active or not will effect the final result.

```{r eval=FALSE, tidy=FALSE}
rst.comb <- rhread("/ln/tongx/housing/soldbydate.combiner")
rst <- rhread("/ln/tongx/housing/soldbydate")
identical(rst, rst.comb)
```
```
[1] TRUE
```

We can see that the final results from these two jobs are identical. We also can convert the results
to be a data frame with following code:

```{r eval=FALSE, tidy=FALSE}
df <- data.frame(  
  date  = sapply(rst, "[[", 1),
  total = sapply(rst, "[[", 2)
)
df <- df[order(df$date, decreasing = FALSE), ]  
df.comb <- data.frame(  
  date  = sapply(rst.comb, "[[", 1),
  total = sapply(rst.comb, "[[", 2)
)
df.comb <- df.comb[order(df.comb$date, decreasing = FALSE), ]
head(df.comb)
head(df)
```
```
   date  total
45    1 272879
50    2 201648
59    3 229829
51    4 180674
60    5 187276
1     6 219149
```
