### Division by State from County Division ###

In the previous two divisions, we started from raw text data, where input key-value pairs were each row
of the text file. In some cases it might be more efficient to go from one subset division method to
another.  Either way, it's a good thing to know how to do.  In this section we'll recreate the 
division by state from the division by county.

Let's start by removing our existing state subsets from the HDFS so there aren't too many copies
floating around.  We can delete files from the HDFS using the `rhdel` function.  It only requires
one argument - the directory to be deleted - and it recursively deletes any subdirectories or files.

We can use `rhls` to see that the division by state is on the HDFS, right where we put it:

```{r eval=FALSE, tidy=FALSE}
rhls("/ln/tongx/housing")
```
```
  permission owner      group     size          modtime                                  file
1 drwxrwxrwt tongx supergroup        0 2014-10-02 14:29            /ln/tongx/housing/byCounty
2 drwxrwxrwt tongx supergroup        0 2014-09-30 14:27             /ln/tongx/housing/byState
3 drwxrwxrwt tongx supergroup        0 2014-10-28 14:07              /ln/tongx/housing/bydate
4 drwxrwxrwt tongx supergroup        0 2014-09-18 23:56         /ln/tongx/housing/meanByState
5 drwxrwxrwt tongx supergroup        0 2014-09-20 11:16        /ln/tongx/housing/meanByCounty
6 -rw-r--r-- tongx supergroup 7.683 mb 2014-09-17 11:11         /ln/tongx/housing/housing.txt
7 drwxrwxrwt tongx supergroup        0 2014-10-28 14:28          /ln/tongx/housing/soldbydate
8 drwxrwxrwt tongx supergroup        0 2014-10-20 16:00 /ln/tongx/housing/soldbydate.combiner
```

We can delete it with the `rhdel` function:

```{r eval=FALSE, tidy=FALSE}
rhdel("/ln/tongx/housing/byState")
```

And we can use `rhls` again to see that we were successful:

```{r eval=FALSE, tidy=FALSE}
rhls("/ln/tongx/housing")
```
```
  permission owner      group     size          modtime                                  file
1 drwxrwxrwt tongx supergroup        0 2014-10-02 14:29            /ln/tongx/housing/byCounty
2 drwxrwxrwt tongx supergroup        0 2014-10-28 14:07              /ln/tongx/housing/bydate
3 drwxrwxrwt tongx supergroup        0 2014-09-18 23:56         /ln/tongx/housing/meanByState
4 drwxrwxrwt tongx supergroup        0 2014-09-20 11:16        /ln/tongx/housing/meanByCounty
5 -rw-r--r-- tongx supergroup 7.683 mb 2014-09-17 11:11         /ln/tongx/housing/housing.txt
6 drwxrwxrwt tongx supergroup        0 2014-10-28 14:28          /ln/tongx/housing/soldbydate
7 drwxrwxrwt tongx supergroup        0 2014-10-20 16:00 /ln/tongx/housing/soldbydate.combiner
```

As long as we're talking about HDFS file management, let's try out a few more functions.  Suppose
we want to make a copy of the original text file on the HDFS.  We can use the
`rhcp` function.  It takes two arguments.  The first is the source, or the directory on HDFS we 
want to copy.  The second is the target, or location for the new copy.

```{r eval=FALSE, tidy=FALSE}
rhcp("/ln/tongx/housing/housing.txt", "/ln/tongx/housing/tmp/housing.txt")
rhls("/ln/tongx/housing/tmp")
```
```
  permission owner      group     size          modtime                              file
1 -rw-r--r-- tongx supergroup 7.683 mb 2014-09-30 15:25 /ln/tongx/housing/tmp/housing.txt
```

We can use `rhmv` to move the text file to a different folder.  This
function also takes two arguments, just like `rhcp`.

```{r eval=FALSE, tidy=FALSE}
rhmv("/ln/tongx/housing/tmp/housing.txt", "/ln/tongx/housing/tmp2/housing.txt")
rhls("/ln/tongx/housing/")
```
```
  permission owner      group     size          modtime                                  file
1 drwxrwxrwt tongx supergroup        0 2014-10-02 14:29            /ln/tongx/housing/byCounty
2 drwxrwxrwt tongx supergroup        0 2014-10-28 14:07              /ln/tongx/housing/bydate
3 drwxrwxrwt tongx supergroup        0 2014-09-18 23:56         /ln/tongx/housing/meanByState
4 drwxrwxrwt tongx supergroup        0 2014-09-20 11:16        /ln/tongx/housing/meanByCounty
5 -rw-r--r-- tongx supergroup 7.683 mb 2014-09-17 11:11         /ln/tongx/housing/housing.txt
6 drwxrwxrwt tongx supergroup        0 2014-10-28 14:28          /ln/tongx/housing/soldbydate
7 drwxrwxrwt tongx supergroup        0 2014-10-20 16:00 /ln/tongx/housing/soldbydate.combiner
8 drwxrwxrwt tongx supergroup        0 2014-09-30 15:25                 /ln/tongx/housing/tmp
9 drwxrwxrwt tongx supergroup        0 2014-09-30 15:28                /ln/tongx/housing/tmp2
```

That's enough file management.  Now let's recreate the division by state from the division by 
county, which is still on the HDFS.

#### Map ####

```{r eval=FALSE, tidy=FALSE}
map9 <- expression({
  lapply(seq_along(map.keys), function(r) {
    key <- attr(map.values[[r]], "state")
    value <- map.values[[r]]
    value$FIPS <- attr(map.values[[r]], "FIPS")
    value$county <- attr(map.values[[r]], "county")
    rhcollect(key, value)
  })
})
```

The most important part of this map expression is the key we assigned.  Our input key was the length 3
character vector containing FIPS code, county name, and state name.  Our output key is the state
name only.  This ensures that the data frames of all the counties belonging to a single state go to
a single reduce task, so that we can combine them into a single data frame for that state.  Meanwhile,
we also want to make the FIPS code and county name columns of our data frame again.

#### Reduce ####

```{r eval=FALSE, tidy=FALSE}
reduce9 <- expression(
  pre = {
    combine <- data.frame()
  },
  reduce = {
    combine <- rbind(combine, do.call(rbind, reduce.values))
  },
  post = {
    rhcollect(reduce.key, combine)
  }
)
```

We can use the same reduce expression that we used in the first division by state.  But keep in mind
that this time, the intermediate key-value pairs are different.  Before there was one key-value pair
for each line of the text file, but now there is one for each county.

#### Execution Function ####
 
```{r eval=FALSE, tidy=FALSE}
mr9 <- rhwatch(
  map      = map9,
  reduce   = reduce9,
  input    = rhfmt("/ln/tongx/housing/byCounty", type = "sequence"),
  output   = rhfmt("/ln/tongx/housing/byState", type = "sequence"),
  mapred   = list( 
    mapred.reduce.tasks = 10
  ),
  readback = FALSE,
  noeval = TRUE
)
```

Here we did something new in the `rhwatch` function.  We set the `noeval` argument to indicate
that we don't want to run this job, we just want to package it to be run later.

You won't see any output, because no commands have been sent to Hadoop.  Instead, the packaged
job has been stored in the `mr5` object.  When we're ready to run the job, we call `rhex()`.

```{r eval=FALSE, tidy=FALSE}
byState <- rhex(mr9, async = FALSE)
```

The first argument to `rhex` is the packaged job we just created.  The second argument `async` 
specifies whether the job should be run asynchronously.  If we set `async = FALSE` then we'll see
continuously updated job status information, and we won't be able to issue any further R commands
until the job completes.  If we set it to `TRUE`, which is the default, the job will run in the 
background while we continue to interact with our R session.  It's similar to the `\&` command in
a Linux shell.

After the job successfully completes, we'll have state subsets in the specified output folder
on the HDFS, just as before, but created in a different way.
